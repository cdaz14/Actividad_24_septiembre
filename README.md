# Sistema de GestiÃ³n de Biblioteca â€” Testing Top Down con Stubs (Python + Pytest)

> **One-liner:** Flujo de prÃ©stamo implementado Top-Down con *stubs* para `auth` y `db`. Tests listos con `pytest` y CI opcional.

## ğŸ¯ Objetivo
Implementar pruebas **Top Down** de un sistema de biblioteca usando **stubs** para simular mÃ³dulos no implementados: autenticaciÃ³n y base de datos.

## ğŸ§± Estructura
```
proyecto_biblioteca/
â”œâ”€â”€ biblioteca_sistema.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ stubs/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database_stub.py
â”‚   â””â”€â”€ auth_stub.py
â”œâ”€â”€ test_top_down.py
â”œâ”€â”€ test_top_down_extra.py
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ tests_ok.png
â”‚   â”œâ”€â”€ analisis_top_down.pdf
â”‚   â””â”€â”€ pytest_output.txt
â””â”€â”€ .github/workflows/python-tests.yml
```
> **Tip:** `.gitignore` incluido para Python/pytest/venv.

## ğŸ§  ImplementaciÃ³n (Top Down)
- `BibliotecaSistema` orquesta el flujo `prestar_libro(usuario_id, libro_id)`.
- Dependencias **inyectadas**: `db`, `auth` (permiten intercambiar *stubs*, *fakes*, *mocks*).
- Orden de validaciones: **auth â†’ disponibilidad â†’ registro**.
- Respuestas de negocio:
  - `"Usuario no autorizado"`
  - `"Libro no disponible"`
  - `"PrÃ©stamo exitoso"`

## ğŸ§ª Pruebas incluidas
- `test_prestamo_exitoso` â€” happy path.
- `test_usuario_no_autorizado` â€” rechazo por auth.
- `test_libro_no_disponible` â€” disponibilidad (ID impar).
- `test_no_llama_db_si_no_autorizado` â€” asegura orden de validaciÃ³n (no toca BD si falla auth).
- `test_registrar_prestamo_invocado_una_vez` â€” *spy* simple para verificar llamada y argumentos.
- `test_tabla_decision_basica` â€” parametrizado de combinaciones clave.
- `test_captura_log_stub` â€” valida *side-effect* del stub (print).

ğŸ‘‰ Ver **screenshot** de ejecuciÃ³n y **anÃ¡lisis** de ventajas en [`/docs`](./docs).

## ğŸ§© Stubs
- `AuthStub.verificar_usuario`: autoriza IDs `> 0`.
- `DatabaseStub.libro_disponible`: disponible si `libro_id % 2 == 0`.
- `DatabaseStub.registrar_prestamo`: simula registro y deja traza por `print`.

## ğŸš€ CÃ³mo correrlo

### Windows (PowerShell)
```powershell
py -m venv .venv
Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
.\.venv\Scripts\Activate.ps1
py -m pip install -U pip -r requirements.txt
py -m pytest -v --tb=short
```

### Ubuntu / Linux
```bash
python3 -m venv .venv
source .venv/bin/activate
python -m pip install -U pip -r requirements.txt
python -m pytest -v --tb=short
```

> Alternativa rÃ¡pida (Ubuntu): `sudo apt install -y python3-pytest && pytest -v`

## ğŸ›  CI (GitHub Actions)
Se incluye workflow en `/.github/workflows/python-tests.yml` para ejecutar `pytest` en PRs y en `main`.

## ğŸ—‚ Entregables (docs/)
- `tests_ok.png` â€” â€œscreenshotâ€ de ejecuciÃ³n.
- `analisis_top_down.pdf` â€” 1 pÃ¡gina de ventajas, buenas prÃ¡cticas y trade-offs.
- `pytest_output.txt` â€” salida completa de la corrida local.

## ğŸ“ˆ Roadmap corto
1. Casos lÃ­mite: IDs invÃ¡lidos (None/str/negativos) y errores de registro.
2. *Fake DB* en memoria para pruebas de integraciÃ³n ligeras.
3. *Mocks* donde importe la secuencia de llamadas.
4. Coverage + *badges* de CI.

---

**Licencia:** MIT â€¢ **Autor:** TÃº âœ¨
